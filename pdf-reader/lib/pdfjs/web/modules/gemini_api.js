// Gemini API Interaction

let apiKey = '';

async function callGeminiAPI(prompt) {
    if (!apiKey) {
        addAiMessage("⚠️ No API key");
        return;
    }
    const loading = document.createElement('div');
    loading.className = 'message ai-message';
    loading.textContent = 'Thinking...';
    chatContainer.appendChild(loading);
    scrollToBottom();
    try {
        const { text, model } = await callGeminiAPIDirect(prompt);
        chatContainer.removeChild(loading);

        // Add model info footer
        const footer = `\n\n_<small style="color: #888;">Generated by ${model}</small>_`;
        await addAiMessage(text + footer, true);
    } catch (e) {
        chatContainer.removeChild(loading);
        addAiMessage(`❌ ${e.message}`);
    }
}

async function callGeminiAPIDirect(prompt) {
    if (!apiKey) throw new Error("No API key");

    // 1. Fetch available models dynamically
    let availableModels = [];
    try {
        const listUrl = `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`;
        const listRes = await fetch(listUrl);
        const listData = await listRes.json();

        if (listData.models) {
            availableModels = listData.models
                .filter(m => m.supportedGenerationMethods && m.supportedGenerationMethods.includes('generateContent'))
                .map(m => m.name.replace('models/', ''));
        }
    } catch (e) {
        console.warn("Failed to fetch model list, using hardcoded defaults", e);
    }

    // 2. Define priority list (Best -> Fast/Free -> Others)
    // We prioritize 2.0 Flash (fastest), then fallbacks
    const preferredOrder = ['gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-1.5-flash-latest', 'gemini-1.5-pro'];

    // 3. Construct the list of models to try
    let modelsToTry = [];

    // First, add preferred models IF they exist in availableModels (or if we failed to fetch list)
    preferredOrder.forEach(pref => {
        if (availableModels.length === 0 || availableModels.includes(pref)) {
            modelsToTry.push(pref);
        }
    });

    // Then add any other available models (like gemma, etc.) that aren't in our preferred list
    availableModels.forEach(m => {
        if (!modelsToTry.includes(m)) {
            modelsToTry.push(m);
        }
    });

    // Fallback if list is empty
    if (modelsToTry.length === 0) {
        modelsToTry = ['gemini-2.0-flash', 'gemini-1.5-pro'];
    }


    let lastError = null;

    for (const model of modelsToTry) {
        try {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;
            const res = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ contents: [{ parts: [{ text: prompt }] }] })
            });

            if (!res.ok) {
                const err = await res.json();
                const errMsg = err.error?.message || `HTTP ${res.status}`;

                // If model not found, continue to next
                if (res.status === 404 || errMsg.includes('not found')) {
                    console.warn(`Model ${model} not found, skipping.`);
                    continue;
                }

                // If quota exceeded (429), continue to next model but log warning
                if (res.status === 429) {
                    console.warn(`Model ${model} quota exceeded (429), skipping.`);
                    lastError = new Error("Quota exceeded. Please try again later or check your API key.");
                    continue;
                }

                throw new Error(errMsg);
            }

            const data = await res.json();
            if (!data.candidates || !data.candidates[0] || !data.candidates[0].content) {
                throw new Error("Invalid API response structure");
            }

            const text = data.candidates[0].content.parts[0].text;
            return { text, model };
        } catch (e) {
            console.warn(`Model ${model} failed:`, e);
            lastError = e;
            // Continue to next model
        }
    }

    throw lastError || new Error("All models failed. Please check your API key.");
}
